= Exercise: Unique Words
:includedir: ../../../../includes
:source-highlighter: rouge
:stem:
:toc: left

== Background

For this exercise we'll develop a module that can

* read text files, one at a time
* identify the set of words that only appear in one of the files
* tell us which words are unique to a given files

The goals of this exercise are to practice

* reading files
* creating and modifying sets and dictionaries
* using set operations (union, intersection, difference)

== Instructions

Start your module with the following code:

----
import re


def get_words(s):
    """ Extract a list of words from string s.

    Args:
        s (str): a string containing one or more words.

    Returns:
        list of str: a list of words from s converted to lower-case.
    """
    words = list()
    s = re.sub(r"--+", " ", s)
    for word in re.findall(r"[\w'-]+", s):
        word = word.strip("'-_")
        if len(word) > 0:
            words.append(word.lower())
    return words
----

Define a class called `UniqueWords` with the following methods:

=== `+++__init__()+++` method

This method should have one parameter, `self`. It should set three attributes:

* `all_words`: initialize this to an empty set. This attribute will keep track of every word you encounter in the files you read in.
* `unique_words`: initialize this to an empty set. This attribute will keep track of words that only appear in a single file.
* `words_by_file`: initialize this to an empty dictionary. This attribute will keep track of the words that occur in a single file.

=== `add_file()` method

This method should have three parameters:

* `self`
* `filename`, a string indicating the path to a file to be read in
* `key`, a string providing a nickname for the file

This method should do the following:

* use a `with` statement to open the specified file for reading and read the file
* call the `get_words()` function to convert the contents of the file to a list of words
* convert that list of words to a set
* store that set in the `words_by_file` attribute, using `key` as the key (recall that `words_by_file` is a dictionary)
* update the `unique_words` attribute so that it no longer contains any words that appear in the file you just read in
* find the set of words that appear in the file you just read in but do not appear in any other file you have read in so far (in the next two steps, I'll refer to these as the "new words")
** __Hint: the words from all the other files should be stored in the `all_words` attribute.__
* update the `unique_words` attribute so that it contains all the new words you just identified
* update the `all_words` attribute so that it contains all the new words you identified

=== `unique()` method

This method should have two parameters:

* `self`
* `key`, a string that is a nickname for a file that was previously read in (in other words, this should be a key in the `words_by_file` dictionary)

This method should return the set of words that is unique to the file specified by `key`. (In other words, it should return the set of words that appear only in the specified file and in no other file that has been read in.)

__Hint: the `unique_words` attribute contains all words that are unique to some file; the `words_by_file` attribute gives you access to all the words from a particular file.__

=== Docstrings

Write a class docstring that describes the purpose of your class and explains the data type and purpose of each attribute.

Write method docstrings for the `add_file()` and `unique()` methods.

== Using your script

The script `analyze_texts.py` gives an example of how your module could be used. This script takes one or more file paths as command line arguments and prints the words that are unique to each file. One set of texts you could apply this script to is the Federalist Papers by Alexander Hamilton, John Jay, and James Madison. These texts are provided for you on ELMS and were extracted from a plain text file provided by Project Gutenberg: http://www.gutenberg.org/ebooks/18. They are provided as a zip file; to use the texts, you will need to unzip the file.

Here's an example of how you could use this script (Windows users, replace `python3` with `python`)

----
python3 analyze_texts.py federalist/federalist_01.txt \
    federalist/federalist_02.txt \
    federalist/federalist_03.txt
----

(The backslashes `\` above tell your terminal that the next line is a continuation of the same command. In PowerShell, use a backtick ``` instead of a backslash. On any platform, if you prefer, you can remove them and just type a really long command on one line.)

On MacOS and in Git Bash on Windows, instead of listing all the files one by one, you can provide a link:https://en.wikipedia.org/wiki/Glob_(programming)["glob pattern"] that matches the files you are interested in:

----
python3 analyze_texts.py federalist/federalist_*.txt
----

Bash or zsh will expand the pattern into a list of files. (Note that PowerShell and cmd.exe on Windows will not expand such a pattern.)
